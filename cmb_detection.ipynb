{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General ------------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image Augmentation -------------------------------------------------------------------------------------------------------\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Deep Learning ------------------------------------------------------------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, initializers, layers, activations, metrics\n",
    "\n",
    "# Bayesian Optimization ----------------------------------------------------------------------------------------------------\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds ---------------------------------------------------------------------------------------------------------\n",
    "rSeed = 0\n",
    "random.seed(rSeed)\n",
    "ia.seed(rSeed)\n",
    "np.random.seed(rSeed)\n",
    "\n",
    "# Set the split fraction between train and test sets -----------------------------------------------------------------------\n",
    "splitFraction = 0.7\n",
    "\n",
    "# Grid search settings -----------------------------------------------------------------------------------------------------\n",
    "gridSearchIterationLimit = float(\"inf\")                 # Set to infinity for searching the whole grid\n",
    "# gridSearchIterationLimit = 10\n",
    "\n",
    "# Random search settings ---------------------------------------------------------------------------------------------------\n",
    "randomSearchIterationLimit = 847                        # Set to 847 for a fair comparison between random search and grid search\n",
    "# randomSearchIterationLimit = 10\n",
    "\n",
    "# Bayesian optimization settings -------------------------------------------------------------------------------------------\n",
    "bayeOptIterationLimit = 25\n",
    "# bayeOptIterationLimit = 10\n",
    "\n",
    "# Deep learning model settings ---------------------------------------------------------------------------------------------\n",
    "regEpochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression Model ---------------------------------------------------------------------------------------------------------------------------------\n",
    "def createRegModel(lr=-1, beta1=0.9, beta2=0.999, epsilon=None, decay=0.0):\n",
    "    try: del model\n",
    "    except:pass\n",
    "    \n",
    "    # Create a sequential model --------------------------------------------------------------------------------------------\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Add a convolutional layer --------------------------------------------------------------------------------------------\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid', input_shape=(41, 41, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='valid'))\n",
    "    # Add another convolution layer ----------------------------------------------------------------------------------------\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='valid'))\n",
    "    # Flatten the output ---------------------------------------------------------------------------------------------------\n",
    "    model.add(layers.Flatten())\n",
    "    # Add dense layers -----------------------------------------------------------------------------------------------------\n",
    "#     model.add(layers.Dense(2))\n",
    "#     model.add(layers.Dense(2))\n",
    "    model.add(layers.Dense(2))\n",
    "    # Add a softmex layer --------------------------------------------------------------------------------------------------\n",
    "    model.add(layers.Softmax())\n",
    "    # Set ADAM as the training algorithm -----------------------------------------------------------------------------------\n",
    "    opt = optimizers.Adam(lr=10**lr, beta_1=beta1, beta_2=beta2, epsilon=epsilon, decay=decay)\n",
    "    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    # Print summary of the model -------------------------------------------------------------------------------------------\n",
    "#     print(model.inputs, model.outputs, model.summary(), sep=\"\\n\\n\")\n",
    "    return model\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### Image Augmentation -------------------------------------------------------------------------------------------------------------------------------\n",
    "def augmentImages(origImages):\n",
    "    seqAug = iaa.Sequential([iaa.OneOf([iaa.AdditiveGaussianNoise(loc=0, scale=(0, 0.1*255)), iaa.GaussianBlur(sigma=(0, 1))]),\n",
    "                            iaa.Affine(rotate=(-25, 25))])\n",
    "    augImages = seqAug.augment_images(origImages)\n",
    "    return augImages\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### Bayesian Optimization ----------------------------------------------------------------------------------------------------------------------------\n",
    "def objectiveFunction(lr=-4, beta1=0.9, beta2=0.999):\n",
    "    # Create the model using specific hyperparameters\n",
    "    model = createRegModel(lr=lr, beta1=beta1, beta2=beta2)\n",
    "    # Train the model\n",
    "    model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs)\n",
    "    # Evaluate model\n",
    "    modelScore = model.evaluate(trainX, categoricalTrainY)\n",
    "    # Return accuracy on train set\n",
    "    return modelScore[1]\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Metrics ------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def evaluateModel(method, predTestY):\n",
    "    tp = tf.keras.metrics.TruePositives()\n",
    "    tn = tf.keras.metrics.TrueNegatives()\n",
    "    fp = tf.keras.metrics.FalsePositives()\n",
    "    fn = tf.keras.metrics.FalseNegatives()\n",
    "    _ = tp.update_state(testY, predTestY)\n",
    "    _ = tn.update_state(testY, predTestY)   \n",
    "    _ = fp.update_state(testY, predTestY)\n",
    "    _ = fn.update_state(testY, predTestY)    \n",
    "    \n",
    "    # True Positives -------------------------------------------------------------------------------------------------------\n",
    "    truePos = tp.result().numpy()\n",
    "    # True Negatives -------------------------------------------------------------------------------------------------------\n",
    "    trueNeg = tn.result().numpy()\n",
    "    # False Positives ------------------------------------------------------------------------------------------------------\n",
    "    falsePos = fp.result().numpy()\n",
    "    # False Negatives ------------------------------------------------------------------------------------------------------\n",
    "    falseNeg = fn.result().numpy()\n",
    "    \n",
    "    # Accuracy -------------------------------------------------------------------------------------------------------------\n",
    "    accuracy = (truePos + trueNeg)/(truePos + trueNeg + falsePos + falseNeg)\n",
    "    # Sensitivity ----------------------------------------------------------------------------------------------------------\n",
    "    sensitivity = (truePos)/(truePos + falseNeg)\n",
    "    # Specificity ----------------------------------------------------------------------------------------------------------\n",
    "    specificity = (trueNeg)/(trueNeg + falsePos)\n",
    "    # Precision ------------------------------------------------------------------------------------------------------------\n",
    "    precision = (truePos)/(truePos + falsePos)\n",
    "    return method, accuracy, sensitivity, specificity, precision\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load dataset -------------------------------------------------------------------------------------------------------------\n",
    "dataX = scipy.io.loadmat(\"dataset_41_41_1_13031.mat\")[\"Input\"]\n",
    "dataY = scipy.io.loadmat(\"dataset_41_41_1_13031.mat\")[\"Target\"]\n",
    "\n",
    "trainX, trainY, testX, testY = [], [], [], []\n",
    "# Create train and test splits ---------------------------------------------------------------------------------------------\n",
    "for i in range(dataX.shape[3]):\n",
    "    if i < math.ceil(dataX.shape[3] * splitFraction):\n",
    "        trainX.append(dataX[:, :, :, i])\n",
    "        trainY.append(dataY[:, i])\n",
    "    else:\n",
    "        testX.append(dataX[:, :, :, i])\n",
    "        testY.append(dataY[:, i])\n",
    "trainX = np.asarray(trainX)\n",
    "trainY = np.reshape(np.asarray(trainY), (-1,))\n",
    "testX = np.asarray(testX)\n",
    "testY = np.reshape(np.asarray(testY), (-1,))\n",
    "\n",
    "# Augment train set images -------------------------------------------------------------------------------------------------\n",
    "trainX = np.concatenate((augmentImages(trainX), trainX))\n",
    "trainY = np.concatenate((trainY, trainY))\n",
    "\n",
    "# Print shapes of train/test sets ------------------------------------------------------------------------------------------\n",
    "print(\"Shape of train data:\", trainX.shape)\n",
    "print(\"Shape of train labels:\", trainY.shape)\n",
    "print(\"Shape of test data:\", testX.shape)\n",
    "print(\"Shape of test label:\", testY.shape)\n",
    "\n",
    "\n",
    "# Convert binary labels into categorical labels ----------------------------------------------------------------------------\n",
    "categoricalTrainY = np.asarray(tf.keras.utils.to_categorical(trainY, num_classes=2))\n",
    "\n",
    "# Create image iterator objects --------------------------------------------------------------------------------------------\n",
    "imgGen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "trainBatchIterator = imgGen.flow(x=trainX, y=categoricalTrainY, batch_size=64, shuffle=True, seed=rSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 18\n",
    "plt.imshow(trainX[index, :, :, 0])\n",
    "print(\"This sample belongs to the class:\", categoricalTrainY[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter space to probe -------------------------------------------------------------------------------------------\n",
    "lrList = [-6, -5, -4, -3, -2, -1, 0]\n",
    "betaList = [0.0001, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.9999]\n",
    "\n",
    "# Implement grid search ----------------------------------------------------------------------------------------------------\n",
    "bestParameters = 0\n",
    "maxAccuracy = 0\n",
    "for i, parameters in enumerate(itertools.product(lrList, betaList, betaList)):\n",
    "    if i == gridSearchIterationLimit: break\n",
    "    print(\"\\nIteration:\", i+1, \"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(\"{'params': {'beta1': \", parameters[1], \", 'beta2': \", parameters[2], \", 'lr': \", parameters[0], \"}}\", sep=\"\")\n",
    "    # Create the model using specific hyperparameters\n",
    "    model = createRegModel(lr=parameters[0], beta1=parameters[1], beta2=parameters[2])\n",
    "    # Train the model\n",
    "    model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs)\n",
    "    # Evaluate model\n",
    "    modelScore = model.evaluate(trainX, categoricalTrainY, verbose=0)\n",
    "    # Keep a record of parameters that give most accurate performance on train set\n",
    "    if modelScore[1] > maxAccuracy:\n",
    "        bestParameters = (i, modelScore[1], parameters)\n",
    "        maxAccuracy = modelScore[1]\n",
    "\n",
    "# Store the parameters found using Grid Search -----------------------------------------------------------------------------\n",
    "gridSearchParameters = bestParameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result ---------------------------------------------------------------------------------------------------------\n",
    "print(\"\\n\")\n",
    "print(\"{\", \"'iteration': \", bestParameters[0]+1, \", 'target': \", bestParameters[1], \", 'params': {'beta1': \", bestParameters[2][1], \", 'beta2': \", bestParameters[2][2], \", 'lr': \", bestParameters[2][0], \"}}\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter space to probe -------------------------------------------------------------------------------------------\n",
    "parameterSetList = [ (np.random.uniform(low=-6, high=0),\n",
    "                      np.random.uniform(low=0.0001, high=0.9999),\n",
    "                      np.random.uniform(low=0.0001, high=0.9999)) for i in range(randomSearchIterationLimit) ]\n",
    "\n",
    "# Implement random search --------------------------------------------------------------------------------------------------\n",
    "bestParameters = 0\n",
    "maxAccuracy = 0\n",
    "for i, parameters in enumerate(parameterSetList):\n",
    "    print(\"\\nIteration:\", i+1, \"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(\"{'params': {'beta1': \", parameters[1], \", 'beta2': \", parameters[2], \", 'lr': \", parameters[0], \"}}\", sep=\"\")\n",
    "    # Create the model using specific hyperparameters\n",
    "    model = createRegModel(lr=parameters[0], beta1=parameters[1], beta2=parameters[2])\n",
    "    # Train the model\n",
    "    model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs)\n",
    "    # Evaluate model\n",
    "    modelScore = model.evaluate(trainX, categoricalTrainY, verbose=0)\n",
    "    # Keep a record of parameters that give most accurate performance on train set\n",
    "    if modelScore[1] > maxAccuracy:\n",
    "        bestParameters = (i, modelScore[1], parameters)\n",
    "        maxAccuracy = modelScore[1]\n",
    "\n",
    "# Store the parameters found using Grid Search -----------------------------------------------------------------------------\n",
    "randomSearchParameters = bestParameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result ---------------------------------------------------------------------------------------------------------\n",
    "print(\"\\n\")\n",
    "print(\"{\", \"'iteration': \", bestParameters[0]+1, \", 'target': \", bestParameters[1], \", 'params': {'beta1': \", bestParameters[2][1], \", 'beta2': \", bestParameters[2][2], \", 'lr': \", bestParameters[2][0], \"}}\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region to probe ------------------------------------------------------------------------------------------------------\n",
    "pbounds = {\"lr\": (-6, 0), \"beta1\": (0.0001, 0.9999), \"beta2\": (0.0001, 0.9999)}\n",
    "\n",
    "# Create the bayesian optimizer --------------------------------------------------------------------------------------------\n",
    "optimizer = BayesianOptimization(f=objectiveFunction, pbounds=pbounds, random_state=rSeed,)\n",
    "utility = UtilityFunction(kind=\"ei\", kappa=2.5, xi=0.0)\n",
    "\n",
    "# Maximize the accuracy ----------------------------------------------------------------------------------------------------\n",
    "for _ in range(bayeOptIterationLimit):\n",
    "    nextPoint = optimizer.suggest(utility)\n",
    "    target = objectiveFunction(**nextPoint)\n",
    "    optimizer.register(params=nextPoint, target=target)\n",
    "    print(target, nextPoint, end=\"\\n\\n\")\n",
    "\n",
    "# Store the parameters found using Grid Search -----------------------------------------------------------------------------\n",
    "bayeOptParameters = (optimizer.max[\"params\"][\"lr\"], optimizer.max[\"params\"][\"beta1\"], optimizer.max[\"params\"][\"beta2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result ---------------------------------------------------------------------------------------------------------\n",
    "print(\"\\n\")\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search --------------------------------------------------------------------------------------------------------------\n",
    "print(\"Evaluating performance using grid search...\", end=\"\")\n",
    "# Create the model using specific hyperparameters\n",
    "model = createRegModel(lr=gridSearchParameters[0], beta1=gridSearchParameters[1], beta2=gridSearchParameters[2])\n",
    "# Train the model\n",
    "model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs, verbose=0)\n",
    "# Evaluate model\n",
    "gridSearchResults = evaluateModel(\"Grid Search\", np.argmax(model.predict(testX), axis = 1))\n",
    "print(\" done!\")\n",
    "\n",
    "\n",
    "# Random search ------------------------------------------------------------------------------------------------------------\n",
    "print(\"Evaluating performance using random search...\", end=\"\")\n",
    "# Create the model using specific hyperparameters\n",
    "model = createRegModel(lr=randomSearchParameters[0], beta1=randomSearchParameters[1], beta2=randomSearchParameters[2])\n",
    "# Train the model\n",
    "model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs, verbose=0)\n",
    "# Evaluate model\n",
    "randomSearchResults = evaluateModel(\"Random Search\", np.argmax(model.predict(testX), axis = 1))\n",
    "print(\" done!\")\n",
    "\n",
    "\n",
    "# Bayesian optimization ----------------------------------------------------------------------------------------------------\n",
    "print(\"Evaluating performance using Bayesian optimization...\", end=\"\")\n",
    "# Create the model using specific hyperparameters\n",
    "model = createRegModel(lr=bayeOptParameters[0], beta1=bayeOptParameters[1], beta2=bayeOptParameters[2])\n",
    "# Train the model\n",
    "model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs, verbose=0)\n",
    "# Evaluate model\n",
    "bayeOptResults = evaluateModel(\"Bayesian Optimization\", np.argmax(model.predict(testX), axis = 1))\n",
    "print(\" done!\\n\")\n",
    "\n",
    "\n",
    "# Compile results ----------------------------------------------------------------------------------------------------------\n",
    "resultsDF = pd.DataFrame([gridSearchResults, randomSearchResults, bayeOptResults], columns = [\"Method\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\"])\n",
    "print(resultsDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
