{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# General ------------------------------------------------------------------------------------------------------------------\nimport os\nimport math\nimport random\nimport itertools\nimport scipy.io\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Image Augmentation -------------------------------------------------------------------------------------------------------\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\n# Deep Learning ------------------------------------------------------------------------------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers, initializers, layers, activations, metrics\n\n# Bayesian Optimization ----------------------------------------------------------------------------------------------------\nfrom bayes_opt import BayesianOptimization\nfrom bayes_opt import UtilityFunction","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set random seeds ---------------------------------------------------------------------------------------------------------\nrSeed = 0\nrandom.seed(rSeed)\nia.seed(rSeed)\nnp.random.seed(rSeed)\n\n# Set the split fraction between train and test sets -----------------------------------------------------------------------\nsplitFraction = 0.7\n\n# Bayesian optimization settings -------------------------------------------------------------------------------------------\nbayeOptIterationLimit = 25\n# bayeOptIterationLimit = 4\n\n# Deep learning model settings ---------------------------------------------------------------------------------------------\nregEpochs = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Convolutional Neural Network Models --------------------------------------------------------------------------------------------------------------\ndef createModel(lr=-1, beta1=0.9, beta2=0.999, epsilon=None, decay=0.0):\n    try: del model\n    except:pass\n    \n    # Create a sequential model --------------------------------------------------------------------------------------------\n    model = tf.keras.models.Sequential()\n    # Add a convolutional layer --------------------------------------------------------------------------------------------\n    model.add(layers.Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid', input_shape=(41, 41, 1)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    model.add(layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='valid'))\n    # Add another convolution layer ----------------------------------------------------------------------------------------\n    if convLayers >= 2:\n        model.add(layers.Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.ReLU())\n        model.add(layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='valid'))\n    # Flatten the output ---------------------------------------------------------------------------------------------------\n    model.add(layers.Flatten())\n    # Add dense layers -----------------------------------------------------------------------------------------------------\n    model.add(layers.Dense(2))\n    if denseLayers >= 2: \n        model.add(layers.Dense(2))\n    if denseLayers >= 3:\n        model.add(layers.Dense(2))\n    # Add a softmex layer --------------------------------------------------------------------------------------------------\n    model.add(layers.Softmax())\n    # Set ADAM as the training algorithm -----------------------------------------------------------------------------------\n    opt = optimizers.Adam(lr=10**lr, beta_1=beta1, beta_2=beta2, epsilon=epsilon, decay=decay)\n    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[metrics.CategoricalAccuracy()])\n    \n    # Print summary of the model -------------------------------------------------------------------------------------------\n#     print(model.inputs, model.outputs, model.summary(), sep=\"\\n\\n\")\n    return model\n### --------------------------------------------------------------------------------------------------------------------------------------------------\n\n\n\n### Image Augmentation -------------------------------------------------------------------------------------------------------------------------------\ndef augmentImages(origImages):\n    seqAug = iaa.Sequential([iaa.OneOf([iaa.AdditiveGaussianNoise(loc=0, scale=(0, 0.1*255)), iaa.GaussianBlur(sigma=(0, 1))]),\n                            iaa.Affine(rotate=(-25, 25))])\n    augImages = seqAug.augment_images(origImages)\n    return augImages\n### --------------------------------------------------------------------------------------------------------------------------------------------------\n\n\n\n### Bayesian Optimization ----------------------------------------------------------------------------------------------------------------------------\ndef objectiveFunction(lr=-4, beta1=0.9, beta2=0.999):\n    # Create the model using specific hyperparameters\n    model = createModel(lr=lr, beta1=beta1, beta2=beta2)\n    # Train the model\n    model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs, verbose=0)\n    # Evaluate model\n    modelScore = model.evaluate(trainX, categoricalTrainY)\n    # Return accuracy on train set\n    return modelScore[1]\n\n\ndef bayeOpt():\n    # Set region to probe ------------------------------------------------------------------------------------------------------\n    pbounds = {\"lr\": (-6, 0), \"beta1\": (0.0001, 0.9999), \"beta2\": (0.0001, 0.9999)}\n    # Create the bayesian optimizer --------------------------------------------------------------------------------------------\n    optimizer = BayesianOptimization(f=objectiveFunction, pbounds=pbounds, random_state=rSeed,)\n    utility = UtilityFunction(kind=\"ei\", kappa=2.5, xi=0.0)\n    # Maximize the accuracy ----------------------------------------------------------------------------------------------------\n    for _ in range(bayeOptIterationLimit):\n        nextPoint = optimizer.suggest(utility)\n        target = objectiveFunction(**nextPoint)\n        optimizer.register(params=nextPoint, target=target)\n#         print(target, nextPoint, end=\"\\n\\n\")\n    return optimizer.max\n### --------------------------------------------------------------------------------------------------------------------------------------------------\n\n\n### Metrics ------------------------------------------------------------------------------------------------------------------------------------------\ndef evaluateModel(convLayers, denseLayers, setName, trueY, predY):\n    tp = tf.keras.metrics.TruePositives()\n    tn = tf.keras.metrics.TrueNegatives()\n    fp = tf.keras.metrics.FalsePositives()\n    fn = tf.keras.metrics.FalseNegatives()\n    _ = tp.update_state(trueY, predY)\n    _ = tn.update_state(trueY, predY)   \n    _ = fp.update_state(trueY, predY)\n    _ = fn.update_state(trueY, predY)    \n    \n    # True Positives -------------------------------------------------------------------------------------------------------\n    truePos = tp.result().numpy()\n    # True Negatives -------------------------------------------------------------------------------------------------------\n    trueNeg = tn.result().numpy()\n    # False Positives ------------------------------------------------------------------------------------------------------\n    falsePos = fp.result().numpy()\n    # False Negatives ------------------------------------------------------------------------------------------------------\n    falseNeg = fn.result().numpy()\n    \n    # Accuracy -------------------------------------------------------------------------------------------------------------\n    accuracy = (truePos + trueNeg)/(truePos + trueNeg + falsePos + falseNeg)\n    # Sensitivity ----------------------------------------------------------------------------------------------------------\n    sensitivity = (truePos)/(truePos + falseNeg)\n    # Specificity ----------------------------------------------------------------------------------------------------------\n    specificity = (trueNeg)/(trueNeg + falsePos)\n    # Precision ------------------------------------------------------------------------------------------------------------\n    precision = (truePos)/(truePos + falsePos)\n    return convLayers, denseLayers, setName, accuracy, sensitivity, specificity, precision\n### --------------------------------------------------------------------------------------------------------------------------------------------------","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Train/Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset -------------------------------------------------------------------------------------------------------------\ndataX = scipy.io.loadmat(\"dataset_41_41_1_13031.mat\")[\"Input\"]\ndataY = scipy.io.loadmat(\"dataset_41_41_1_13031.mat\")[\"Target\"]\n\ntrainX, trainY, testX, testY = [], [], [], []\n# Create train and test splits ---------------------------------------------------------------------------------------------\nfor i in range(dataX.shape[3]):\n    if i < math.ceil(dataX.shape[3] * splitFraction):\n        trainX.append(dataX[:, :, :, i])\n        trainY.append(dataY[:, i])\n    else:\n        testX.append(dataX[:, :, :, i])\n        testY.append(dataY[:, i])\ntrainX = np.asarray(trainX)\ntrainY = np.reshape(np.asarray(trainY), (-1,))\ntestX = np.asarray(testX)\ntestY = np.reshape(np.asarray(testY), (-1,))\n\n# Augment train set images -------------------------------------------------------------------------------------------------\ntrainX = np.concatenate((augmentImages(trainX), trainX))\ntrainY = np.concatenate((trainY, trainY))\n\n# Print shapes of train/test sets ------------------------------------------------------------------------------------------\nprint(\"Shape of train data:\", trainX.shape)\nprint(\"Shape of train labels:\", trainY.shape)\nprint(\"Shape of test data:\", testX.shape)\nprint(\"Shape of test label:\", testY.shape)\n\n\n# Convert binary labels into categorical labels ----------------------------------------------------------------------------\ncategoricalTrainY = np.asarray(tf.keras.utils.to_categorical(trainY, num_classes=2))\n\n# Create image iterator objects --------------------------------------------------------------------------------------------\nimgGen = tf.keras.preprocessing.image.ImageDataGenerator()\ntrainBatchIterator = imgGen.flow(x=trainX, y=categoricalTrainY, batch_size=64, shuffle=True, seed=rSeed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preview Samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 18\nplt.imshow(trainX[index, :, :, 0])\nprint(\"This sample belongs to the class:\", categoricalTrainY[index])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compare Structures"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN Structures to compare: (number of convolution layers, number of dense layers) ----------------------------------------\nmodelStructures = [(1,1), (1,2), (1,3), (2,1), (2,2), (2,3)]\n\n# Evaluate CNN Structures --------------------------------------------------------------------------------------------------\nresultsList = []\nfor i, (convLayers, denseLayers) in enumerate(modelStructures):\n    print(\"\\nEvaluating Model: {Convolution layers: \",convLayers, \",\", \" Dense Layers: \", denseLayers, \"} ---------------------------------------------------------------------\",sep=\"\")\n    # Perform Bayesian optimization ----------------------------------------------------------------------------------------\n    bayeOptParameters = bayeOpt()\n    # Create the model using the optimum hyper-paramters -------------------------------------------------------------------\n    model = createModel(lr=bayeOptParameters[\"params\"][\"lr\"], beta1=bayeOptParameters[\"params\"][\"beta1\"], beta2=bayeOptParameters[\"params\"][\"beta2\"])\n    # Train the model ------------------------------------------------------------------------------------------------------\n    model.fit_generator(generator=trainBatchIterator, steps_per_epoch=len(trainBatchIterator), epochs=regEpochs, verbose=0)\n    # Evaluate the model ---------------------------------------------------------------------------------------------------\n    resultsList.append(evaluateModel(convLayers, denseLayers, \"Train Set\", trainY, np.argmax(model.predict(trainX), axis = 1)))\n    resultsList.append(evaluateModel(convLayers, denseLayers, \"Test Set\", testY, np.argmax(model.predict(testX), axis = 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile results ----------------------------------------------------------------------------------------------------------\nresultsDF = pd.DataFrame(resultsList, columns = [\"Number of Convolution Layers\", \"Number of Dense Layers\", \"Set\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\"])\nprint(resultsDF)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}